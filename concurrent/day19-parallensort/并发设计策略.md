## 线程划分方式

### 按数量切分
对于大量处理的数据，可以按照任务数量区分，简单来说如果我们要处理n个任务，总计有m个线程，那么我们可以简单的规划每个线程处理n/m个任务。

如下图

![https://cdn.llfc.club/1705459243909.jpg](https://cdn.llfc.club/1705459243909.jpg)

这种方式用来划分大量相同任务时可以采用，但是有些逻辑并不是完全可以靠数量划分的，比如递归逻辑。

### 递归划分

前文我们提及了快速排序的并行实现，包括利用async和线程池的方式。

快速排序算法含有两大基本步骤：

选定一个元素为比较的基准元素；

将数据集按大小划分为前后两部分，重新构成新序列，再针对这两个部分递归排序。

数据划分无法从一开始就并行化，因为数据只有经过处理后，我们才清楚它会归入哪个部分。

若我们要并行化这个算法，就需要利用递归操作的固有性质。

每层递归均会涉及更多的quick_sort()函数调用，因为我们需对基准元素前后两部分都进行排序。

由于这些递归调用所访问的数据集互不相关，因此它们完全独立，正好吻合并发程序的首选执行方式。

下图展示了以递归方式划分数据。

![https://cdn.llfc.club/1705461120545.jpg](https://cdn.llfc.club/1705461120545.jpg)

在早期我们实现并行递归的快速排序，那段代码每深入一层递归，都借std::async()生成新的异步任务处理前半部分数据，而后部分则继续用本线程计算后半部分数据。

我们通过std::async()让C++线程库自主决定，是另起新线程执行新任务，还是在原线程上同步运行。

这点相当重要：假设排序操作的数据集非常庞大，若每次递归都生成新线程，则势必令线程数目激增。

我们将通过后文的性能分析了解到，太多线程反而可能令应用程序变慢。

如果数据集着实庞大，还有可能消耗殆尽全部线程。按上述递归方式来切分数据是不错的思路，但需约束线程数目的增长，不可任其数目无限膨胀。

此例比较简单，std::async()足以应付，但它不是唯一选择。

后来我们觉得开辟过多的线程并不合适，采用了线程池。

并发编程的作者提出的另一种做法是，根据std::hardware_concurrency()函数的返回值设定线程的数目，实现了accumulate()的并行版本。

接着，我们采用之前实现的线程安全的栈容器，将尚未排序的数据段压入其中，而不是启动新线程以执行递归调用。

若某线程无所事事，或因全部数据段均已处理妥当，或因它正等着另一数据段完成排序，若是后者，该线程即从栈容器取出所等的数据段自行排序。

``` cpp
template<typename T>
struct sorter    
{
	struct chunk_to_sort
	{
		std::list<T> data;
		std::promise<std::list<T> > promise;
	};
	thread_safe_stack<chunk_to_sort> chunks;    //⇽-- - 2
	std::vector<std::thread> threads;   // ⇽-- - 3
	unsigned const max_thread_count;
	std::atomic<bool> end_of_data;
	sorter() :
		max_thread_count(std::thread::hardware_concurrency() - 1),
		end_of_data(false)
	{}
	~sorter()    //⇽-- - 4
	{
		end_of_data = true;     //⇽-- - 5
		for (unsigned i = 0; i < threads.size(); ++i)
		{
			threads[i].join();    //⇽-- - 6
		}
	}
	void try_sort_chunk()
	{
		std::shared_ptr<chunk_to_sort> chunk = chunks.try_pop();    //⇽-- - 7
		if (chunk)
		{
			sort_chunk(chunk);    //⇽-- - 8
		}
	}
	std::list<T> do_sort(std::list<T>& chunk_data)    //⇽-- - 9
	{
		if (chunk_data.empty())
		{
			return chunk_data;
		}
		std::list<T> result;
		result.splice(result.begin(),chunk_data,chunk_data.begin());
		T const& partition_val = *result.begin();
		typename std::list<T>::iterator divide_point =  //⇽-- - 10
			std::partition(chunk_data.begin(),chunk_data.end(),
						   [&](T const& val) {return val < partition_val; });
		chunk_to_sort new_lower_chunk;
		new_lower_chunk.data.splice(new_lower_chunk.data.end(),
									chunk_data,chunk_data.begin(),
									divide_point);
		std::future<std::list<T> > new_lower =
			new_lower_chunk.promise.get_future();
		chunks.push(std::move(new_lower_chunk));   // ⇽-- - 11
		if (threads.size() < max_thread_count)    // ⇽-- - 12
		{
			threads.push_back(std::thread(&sorter<T>::sort_thread,this));
		}
		std::list<T> new_higher(do_sort(chunk_data));
		result.splice(result.end(),new_higher);
		while (new_lower.wait_for(std::chrono::seconds(0)) !=
			  std::future_status::ready)    //⇽-- - 13
		{
			try_sort_chunk();   // ⇽-- - 14
		}
		result.splice(result.begin(),new_lower.get());
		return result;
	}
	void sort_chunk(std::shared_ptr<chunk_to_sort > const& chunk)
	{
		chunk->promise.set_value(do_sort(chunk->data));    //⇽-- - 15
	}
	void sort_thread()
	{
		while (!end_of_data)    //⇽-- - 16
		{
			try_sort_chunk();    // ⇽-- - 17
			//交出时间片
			std::this_thread::yield();    //⇽-- - 18
		}
	}
};
template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input)    //⇽-- - 19
{
	if (input.empty())
	{
		return input;
	}
	sorter<T> s;
	return s.do_sort(input);    //⇽-- - 20
}
```

本例中，parallel_quick_sort()函数(19处)把绝大部分功能委托给sorter类(1处)，后者通过栈容器管理待排序的数据段(2处)，并集中管控多个线程以并发执行任务(3处)，从而以便捷的操作方式给出了代码实现。

本例中，主要工作由成员函数do_sort()负责(9处)，它借标准库的std::partition()函数完成数据分段(10处)。

do_sort()将新划分出来的数据段压入栈容器(11处)，但没有为每个数据段都专门生成新线程，而仅当仍存在空闲的处理器时(12处)才生成新线程。

因为划分出的前半部分数据可能会由别的线程处理，所以我们需要等待它完成排序而进入就绪状态(13处)。

如果当前线程是整个程序中仅有的线程，或者其他线程都正忙于别的任务，那么这一等待行为则需妥善处理，在当前线程的等待期间，我们让它试着从栈容器取出数据进行处理(14处)。

try_sort_chunk()先从栈容器弹出一段数据(7处)并对其进行排序(8处)，再把结果存入附属该段的promise中(15处)，使之准备就绪，以待提取。

向栈容器压入数据段与取出相关结果相互对应，两项操作均由同一个线程先后执行(11和12处)。